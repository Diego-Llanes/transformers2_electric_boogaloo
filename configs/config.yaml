# `uv run src/main.py --profiles lev_transformer`
# --- Profiles ---
profiles:
  transformer:
    model: models/transformer.yaml
  gru:
    model: models/gru.yaml
  lstm:
    model: models/lstm.yaml
  rnn:
    model: models/rnn.yaml
  ins_transformer:
    model: models/ins_transformer.yaml
  lev_transformer:
    model: models/lev_transformer.yaml
  corr_transformer:
    model: models/corr_transformer.yaml

# --- General ---
bs: 10
epochs: 100_000 # just go until patience exceeded
?debug: false  # tip: use "--debug" on the command line to set this
sample_temperature: 0.8
corruption_prob: 0.15
patience: 20
eval_samples: 5

# --- Logging ---
logger: console
logdir: logs
run_name: debug
experiment: NLP Final Project

wandb_entity: diegollanes

# --- Dataset ---
split_percentages: [0.8, 0.1, 0.1]
dataset:
  _target_: dataset.dataset.TinyLanguageDataset
  txt_path: "data/frankenstien.txt"
  # txt_path: "data/gutenberg_top100_cleaned/"
  seq_len: 300
  stride: 20

# --- Optimizer ---
optimizer:
  _target_: torch.optim.AdamW
  lr: 0.001
