# `uv run src/main.py --profiles lev_transformer`
# --- Profiles ---
profiles:
  transformer:
    model: models/transformer.yaml
  gru:
    model: models/gru.yaml
  lstm:
    model: models/lstm.yaml
  rnn:
    model: models/rnn.yaml
  ins_transformer:
    model: models/ins_transformer.yaml
  lev_transformer:
    model: models/lev_transformer.yaml
  corr_transformer:
    model: models/corr_transformer.yaml

# --- General ---
bs: 10
epochs: 100
?debug: false  # tip: use "--debug" on the command line to set this
sample_temperature: 0.8
corruption_prob: 0.15

# --- Logging ---
logger: console
logdir: logs
run_name: debug
experiment: transformer

# --- Dataset ---
split_percentages: [0.8, 0.1, 0.1]
dataset:
  _target_: dataset.dataset.TinyLanguageDataset
  txt_path: "data/frankenstien.txt"
  # txt_path: "data/gutenberg_top100_cleaned/"
  seq_len: 300
  stride: 20

# --- Model ---
# model:
#   # _target_: models.insertion_transformer.InsertionTransformer
#   _target_: models.levenshtein_transformer.LevenshteinTransformer
#   # _target_: models.transformer.BabyGPT
#   seq_len: 300
#   n_layers: 2
#   n_heads: 4
#   embedding_dim: 64
#   dim_ff: 256
#   dropout: 0.1

# --- Optimizer ---
optimizer:
  _target_: torch.optim.AdamW
  lr: 0.001
